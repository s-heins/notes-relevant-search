{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading TMDB.json into local Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported my_utils module\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'my_utils' from '/Users/heinss/private-projects/notes-relevant-search/Jupyter/my_utils.py'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(my_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import my_utils\n",
    "from my_utils import host, index, indexBaseUrl, headers\n",
    "import requests  # HTTP lib\n",
    "import json  # json parsing\n",
    "\n",
    "# docker run --name elasticsearch --net elastic -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e \"xpack.security.enabled=false\" -t docker.elastic.co/elasticsearch/elasticsearch:8.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"settings\": {\"number_of_shards\": 1, \"index\": {\"analysis\": {}}}, \"mappings\": {}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract():\n",
    "    f = open('tmdb.json')\n",
    "    if f:\n",
    "        return json.loads(f.read())\n",
    "\n",
    "\n",
    "def reindex(analysisSettings={}, mappingSettings={}, movieDict={}):\n",
    "    settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"index\": {\n",
    "                \"analysis\": analysisSettings,\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": mappingSettings\n",
    "    }\n",
    "\n",
    "    settingsJson = json.dumps(settings)\n",
    "\n",
    "    # print(mappingSettings)\n",
    "    # if mappingSettings:\n",
    "        # settings['mappings'] = json.dumps(mappingSettings)\n",
    "        \n",
    "    print(settingsJson)\n",
    "\n",
    "    requests.delete(host + index)\n",
    "    requests.put(host + index, data=settingsJson, headers=headers)\n",
    "\n",
    "    bulkMovies = \"\"\n",
    "    for id, movie in movieDict.items():\n",
    "        addCmd = {\"index\": {\"_id\": movie[\"id\"]}}\n",
    "        bulkMovies += json.dumps(addCmd) + \"\\n\" + json.dumps(movie) + \"\\n\"\n",
    "\n",
    "    response = requests.post(indexBaseUrl + \"/_bulk\",\n",
    "                             data=bulkMovies, headers=headers)\n",
    "    return response\n",
    "\n",
    "\n",
    "movieDict = extract()\n",
    "reindex(movieDict=movieDict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str):\n",
    "    hits = my_utils.getSearchHits(query)\n",
    "    my_utils.parseSearchHits(hits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevanceScore\tMovie Title\n",
      "1\t85.6\t\tAliens\n",
      "2\t73.7\t\tThe Basketball Diaries\n",
      "3\t71.3\t\tCowboys & Aliens\n",
      "4\t61.1\t\tMonsters vs Aliens\n",
      "5\t53.5\t\tAliens vs Predator: Requiem\n",
      "6\t53.5\t\tAliens in the Attic\n",
      "7\t45.2\t\tDances with Wolves\n",
      "8\t45.2\t\tFriends with Benefits\n",
      "9\t45.2\t\tFire with Fire\n",
      "10\t45.2\t\tFriends with Kids\n",
      "11\t39.6\t\tInterview with the Vampire\n",
      "12\t39.6\t\tFrom Russia With Love\n",
      "13\t39.6\t\tGone with the Wind\n",
      "14\t39.6\t\tJust Go With It\n",
      "15\t39.6\t\tMy Week with Marilyn\n"
     ]
    }
   ],
   "source": [
    "userSearch = 'basketball with cartoon aliens'\n",
    "baseQuery = {\n",
    "    \"query\": {\n",
    "        \"multi_match\": {\n",
    "            \"query\": userSearch,\n",
    "            \"fields\": [\"title^10\", \"overview\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "query = my_utils.mergeDicts(baseQuery, {\"size\": 15})\n",
    "search(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(query: str): \n",
    "    url = indexBaseUrl + \"/_validate/query?explain\"\n",
    "    response = requests.get(url, data = json.dumps(query), headers=headers)\n",
    "    my_utils.toJsonPrettyPrint(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_shards\": {\n",
      "    \"total\": 1,\n",
      "    \"successful\": 1,\n",
      "    \"failed\": 0\n",
      "  },\n",
      "  \"valid\": true,\n",
      "  \"explanations\": [\n",
      "    {\n",
      "      \"index\": \"tmdb\",\n",
      "      \"valid\": true,\n",
      "      \"explanation\": \"((title:basketball title:with title:cartoon title:aliens)^10.0 | (overview:basketball overview:with overview:cartoon overview:aliens))\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "explain(baseQuery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tokens\": [\n",
      "    {\n",
      "      \"token\": \"fire\",\n",
      "      \"start_offset\": 0,\n",
      "      \"end_offset\": 4,\n",
      "      \"type\": \"<ALPHANUM>\",\n",
      "      \"position\": 0\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"with\",\n",
      "      \"start_offset\": 5,\n",
      "      \"end_offset\": 9,\n",
      "      \"type\": \"<ALPHANUM>\",\n",
      "      \"position\": 1\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"fire\",\n",
      "      \"start_offset\": 10,\n",
      "      \"end_offset\": 14,\n",
      "      \"type\": \"<ALPHANUM>\",\n",
      "      \"position\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "analyzeQuery = {\n",
    "    \"analyzer\": \"standard\",\n",
    "    \"text\": \"Fire with Fire\"\n",
    "}\n",
    "response = requests.get(indexBaseUrl + \"/_analyze\", data=json.dumps(analyzeQuery), headers=headers)\n",
    "my_utils.toJsonPrettyPrint(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Re-indexing with the English analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"settings\": {\"number_of_shards\": 1, \"index\": {\"analysis\": {}}}, \"mappings\": {\"properties\": {\"title\": {\"type\": \"text\", \"analyzer\": \"english\"}, \"overview\": {\"type\": \"text\", \"analyzer\": \"english\"}}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappingSettings = {\n",
    "    \"properties\": {\n",
    "        \"title\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"english\"\n",
    "        },\n",
    "        \"overview\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"english\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "movieDict=extract()\n",
    "reindex(mappingSettings=mappingSettings, movieDict=movieDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the title now uses the english analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tmdb\": {\n",
      "    \"mappings\": {\n",
      "      \"title\": {\n",
      "        \"full_name\": \"title\",\n",
      "        \"mapping\": {\n",
      "          \"title\": {\n",
      "            \"type\": \"text\",\n",
      "            \"analyzer\": \"english\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "currentTitleMapping = requests.get(indexBaseUrl + \"/_mapping/field/title\")\n",
    "my_utils.toJsonPrettyPrint(currentTitleMapping.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-analyzing \"Fire with Fire\" with the new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tokens\": [\n",
      "    {\n",
      "      \"token\": \"fire\",\n",
      "      \"start_offset\": 0,\n",
      "      \"end_offset\": 4,\n",
      "      \"type\": \"<ALPHANUM>\",\n",
      "      \"position\": 0\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"fire\",\n",
      "      \"start_offset\": 10,\n",
      "      \"end_offset\": 14,\n",
      "      \"type\": \"<ALPHANUM>\",\n",
      "      \"position\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "analyzeQuery = {\n",
    "    \"field\": \"title\",\n",
    "    \"text\": \"Fire with Fire\"\n",
    "}\n",
    "response = requests.get(indexBaseUrl + \"/_analyze\", data=json.dumps(analyzeQuery), headers=headers)\n",
    "my_utils.toJsonPrettyPrint(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"With\" is now also removed from the title and overview tokens in the explanation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_shards\": {\n",
      "    \"total\": 1,\n",
      "    \"successful\": 1,\n",
      "    \"failed\": 0\n",
      "  },\n",
      "  \"valid\": true,\n",
      "  \"explanations\": [\n",
      "    {\n",
      "      \"index\": \"tmdb\",\n",
      "      \"valid\": true,\n",
      "      \"explanation\": \"((title:basketbal title:cartoon title:alien)^10.0 | (overview:basketbal overview:cartoon overview:alien))\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "explain(baseQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevanceScore\tMovie Title\n",
      "1\t78.8\t\tThe Basketball Diaries\n",
      "2\t74.1\t\tAlien\n",
      "3\t74.1\t\tAliens\n",
      "4\t74.1\t\tAlien³\n",
      "5\t59.7\t\tCowboys & Aliens\n",
      "6\t59.7\t\tAliens in the Attic\n",
      "7\t59.7\t\tAlien: Resurrection\n",
      "8\t50.0\t\tMonsters vs Aliens\n",
      "9\t43.0\t\tAliens vs Predator: Requiem\n",
      "10\t43.0\t\tAVP: Alien vs. Predator\n",
      "11\t12.9\t\tSpace Jam\n",
      "12\t 7.5\t\tGrown Ups\n",
      "13\t 7.5\t\tSpeed Racer\n",
      "14\t 7.2\t\tSemi-Pro\n",
      "15\t 7.2\t\tThe Flintstones\n"
     ]
    }
   ],
   "source": [
    "search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "userSearch = 'basketball with cartoon aliens'\n",
    "explainSearchQuery = {\n",
    "    \"query\": {\n",
    "        \"multi_match\": {\n",
    "            \"query\": userSearch,\n",
    "            \"fields\": [\"title^10\", \"overview\"]\n",
    "        }\n",
    "    },\n",
    "    \"explain\": \"true\",\n",
    "    \"size\": 15\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw `_explanation` contents from hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"value\": 78.76023,\n",
      "  \"description\": \"max of:\",\n",
      "  \"details\": [\n",
      "    {\n",
      "      \"value\": 78.76023,\n",
      "      \"description\": \"sum of:\",\n",
      "      \"details\": [\n",
      "        {\n",
      "          \"value\": 78.76023,\n",
      "          \"description\": \"weight(title:basketbal in 784) [PerFieldSimilarity], result of:\",\n",
      "          \"details\": [\n",
      "            {\n",
      "              \"value\": 78.76023,\n",
      "              \"description\": \"score(freq=1.0), computed as boost * idf * tf from:\",\n",
      "              \"details\": [\n",
      "                {\n",
      "                  \"value\": 22.0,\n",
      "                  \"description\": \"boost\",\n",
      "                  \"details\": []\n",
      "                },\n",
      "                {\n",
      "                  \"value\": 7.6180873,\n",
      "                  \"description\": \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\",\n",
      "                  \"details\": [\n",
      "                    {\n",
      "                      \"value\": 1,\n",
      "                      \"description\": \"n, number of documents containing term\",\n",
      "                      \"details\": []\n",
      "                    },\n",
      "                    {\n",
      "                      \"value\": 3051,\n",
      "                      \"description\": \"N, total number of documents with field\",\n",
      "                      \"details\": []\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"value\": 0.4699356,\n",
      "                  \"description\": \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\",\n",
      "                  \"details\": [\n",
      "                    {\n",
      "                      \"value\": 1.0,\n",
      "                      \"description\": \"freq, occurrences of term within document\",\n",
      "                      \"details\": []\n",
      "                    },\n",
      "                    {\n",
      "                      \"value\": 1.2,\n",
      "                      \"description\": \"k1, term saturation parameter\",\n",
      "                      \"details\": []\n",
      "                    },\n",
      "                    {\n",
      "                      \"value\": 0.75,\n",
      "                      \"description\": \"b, length normalization parameter\",\n",
      "                      \"details\": []\n",
      "                    },\n",
      "                    {\n",
      "                      \"value\": 2.0,\n",
      "                      \"description\": \"dl, length of field\",\n",
      "                      \"details\": []\n",
      "                    },\n",
      "                    {\n",
      "                      \"value\": 2.1740413,\n",
      "                      \"description\": \"avgdl, average length of field\",\n",
      "                      \"details\": []\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(hitshits[0]['_explanation'], indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prettier and with maxLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hitshits = my_utils.getSearchHitsHits(explainSearchQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: The Basketball Diaries\n",
      "└──78.76023 (max of:)\n",
      "   └──78.76023 (sum of:)\n",
      "      └──78.76023 (weight(title:basketbal in 784) [PerFieldSimilarity], result of:)\n",
      "         └──78.76023 (score(freq=1.0), computed as boost * idf * tf from:)\n",
      "            └──22.0 (boost)\n",
      "            └──7.6180873 (idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:)\n",
      "               └──1 (n, number of documents containing term)\n",
      "               └──3051 (N, total number of documents with field)\n",
      "            └──0.4699356 (tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:)\n",
      "               └──1.0 (freq, occurrences of term within document)\n",
      "               └──1.2 (k1, term saturation parameter)\n",
      "               └──0.75 (b, length normalization parameter)\n",
      "               └──2.0 (dl, length of field)\n",
      "               └──2.1740413 (avgdl, average length of field)\n"
     ]
    }
   ],
   "source": [
    "my_utils.titleAndExplanation(hitshits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: The Basketball Diaries\n",
      "└──78.76023 (max of:)\n",
      "   └──78.76023 (sum of:)\n",
      "      └──78.76023 (weight(title:basketbal in 784) [PerFieldSimilarity], result of:)\n",
      "         └──78.76023 (score(freq=1.0), computed as boost * idf * tf from:)\n",
      "            └──22.0 (boost)\n",
      "               ...\n",
      "            └──7.6180873 (idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:)\n",
      "               ...\n",
      "            └──0.4699356 (tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:)\n",
      "               ...\n"
     ]
    }
   ],
   "source": [
    "my_utils.titleAndExplanation(hitshits[0], 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
